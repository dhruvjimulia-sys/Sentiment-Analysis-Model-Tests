{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "orig_nbformat": 4,
    "colab": {
      "name": "transformers.ipynb",
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "xoZul_o22nIO"
      },
      "source": [
        "# Learn GridSearch in order to learn these things\n",
        "# Things to try: Stop Word Removal, Mixed Case, Replacing actual sentiment numbers with 0 or 1\n",
        "# Importing relevant libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "\n",
        "!pip install -q transformers\n",
        "from transformers import BertTokenizer\n",
        "from transformers import TFBertModel\n",
        "\n",
        "import pickle\n",
        "from tensorflow import keras\n",
        "from keras.layers import Dense, Dropout, BatchNormalization\n",
        "from keras.optimizers import Adam\n",
        "from keras.losses import SparseCategoricalCrossentropy\n",
        "from keras.metrics import SparseCategoricalAccuracy\n",
        "\n",
        "import os\n",
        "\n",
        "# Global Variables\n",
        "data_size = 50000\n",
        "model_name = \"bert-base-cased\""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cuja9Dki27x7",
        "outputId": "4710132e-7c2d-424c-cf3e-92f73321576a"
      },
      "source": [
        "print(\"Downloading dataset\")\n",
        "!gdown --id 1ne-nT-rA26lzZTVAnWk9bKOFs6XdqlL9"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading dataset\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1ne-nT-rA26lzZTVAnWk9bKOFs6XdqlL9\n",
            "To: /content/treebank.csv\n",
            "14.1MB [00:00, 124MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SpUDDnK7-ztX"
      },
      "source": [
        "# Preprocessing functions\n",
        "def tokenize(text_doc):\n",
        "    # returns generator object for optimization\n",
        "    return (token.lemma_.lower() for token in text_doc if (not token.is_stop) & (token.lemma_ != '-PRON-') & (not token.is_punct) & (not token.text.isdigit()))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdRRx8RrZVrd"
      },
      "source": [
        "df = pd.read_csv('/content/treebank.csv')\n",
        "df = df.iloc[:data_size]\n",
        "\n",
        "phrases = np.array(df[\"phrases\"])\n",
        "sentiment_labels = np.array(df[\"labels\"])\n",
        "\n",
        "preprocessed_phrases = np.array([tokenize() for doc in nlp.pipe(phrases)])"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7nW90gPpaVMd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b046819e-38a9-4e62-c0ae-8c169af16bcf"
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "\n",
        "max_token_len = np.max(np.array([len(tokenizer.encode(phrase)) for phrase in phrases]))\n",
        "print(max_token_len)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "65\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wvh2T_DJFCPK",
        "outputId": "2bc0c7cb-510d-4af1-bf5d-6b2c45f6c7f0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "tokenizer.tokenize(\"This is a sentence: with really, inappropriate punctuation.\")"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['This',\n",
              " 'is',\n",
              " 'a',\n",
              " 'sentence',\n",
              " ':',\n",
              " 'with',\n",
              " 'really',\n",
              " ',',\n",
              " 'inappropriate',\n",
              " 'pu',\n",
              " '##nc',\n",
              " '##tu',\n",
              " '##ation',\n",
              " '.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UugPlTdrZvAN"
      },
      "source": [
        "# Encode dataset\n",
        "token_ids = np.zeros(shape=(len(phrases), max_token_len), dtype=np.int32)\n",
        "for index, phrase in enumerate(phrases):\n",
        "  encoded = tokenizer.encode(phrase)\n",
        "  token_ids[index][0 : len(encoded)] = encoded"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-SuYdFAxUL1"
      },
      "source": [
        "sentiment_labels = np.array([round(value) for value in sentiment_labels])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gG4-uUtym41M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "821ef509-ad2f-4ec4-9224-414dd16df1e3"
      },
      "source": [
        "# Split into training, testing and validation data\n",
        "X_train, X_test, y_train, y_test = train_test_split(token_ids, sentiment_labels, test_size=0.2)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25)\n",
        "print(len(X_train), len(X_test), len(X_val))\n",
        "print(len(y_train), len(y_test), len(y_val))\n",
        "\n",
        "training_data_X = {\"input_ids\": X_train, \"attention_masks\": (X_train != 0).astype(np.int32)}\n",
        "testing_data_X = {\"input_ids\": X_test, \"attention_masks\": (X_test != 0).astype(np.int32)}\n",
        "validation_data_X = {\"input_ids\": X_val, \"attention_masks\": (X_val != 0).astype(np.int32)}"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "30000 10000 10000\n",
            "30000 10000 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ffSA_v6FbAP-",
        "outputId": "0911c4b9-3779-4011-dc48-7e06b639de9f"
      },
      "source": [
        "base_bert_model = TFBertModel.from_pretrained(model_name)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGAZur3KfKSY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1606efa5-33b3-4627-f2c3-e78c30908aab"
      },
      "source": [
        "for value in range(5):\n",
        "  sample_word_embedding = np.array(base_bert_model(np.array([tokenizer.encode(\"Why is my life like this\")])).last_hidden_state)[0][value]\n",
        "  max = np.max(sample_word_embedding)\n",
        "  min = np.min(sample_word_embedding)\n",
        "  print(max, min)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7.3147755 -6.191269\n",
            "1.2527395 -8.161622\n",
            "1.9135013 -7.377506\n",
            "1.9216245 -8.130331\n",
            "1.2145783 -8.520856\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B89EdgiDaqc1"
      },
      "source": [
        "class BertModel(keras.Model):\n",
        "  def __init__(self, dropout_prob = 0.1, **kwargs):\n",
        "    super(BertModel, self).__init__()\n",
        "    self.bert = base_bert_model\n",
        "    self.dropout = Dropout(rate = dropout_prob)\n",
        "    self.dense = Dense(1, activation=\"sigmoid\")\n",
        "\n",
        "  def call(self ,inputs, **kwargs):\n",
        "    sequence_tokens, pooled_output = self.bert(inputs, **kwargs).values()\n",
        "    pooled_output = self.dropout(pooled_output, training=kwargs.get(\"training\", False))\n",
        "    sentiment_label = self.dense(pooled_output)\n",
        "    return sentiment_label\n",
        "\n",
        "bert_complete_model = BertModel()\n",
        "bert_complete_model.compile(optimizer=Adam(learning_rate=3e-5, epsilon=1e-08), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8HQ9h6pAhvhK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b0c5d8d-3918-4fd6-aeef-651d90b7066b"
      },
      "source": [
        "history = bert_complete_model.fit(training_data_X, y_train, epochs=1, batch_size=25, validation_data=(validation_data_X, y_val))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "1200/1200 [==============================] - ETA: 0s - loss: 0.4789 - accuracy: 0.7651WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "1200/1200 [==============================] - 510s 377ms/step - loss: 0.4789 - accuracy: 0.7651 - val_loss: 0.4023 - val_accuracy: 0.8150\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}