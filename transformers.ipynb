{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "orig_nbformat": 4,
    "colab": {
      "name": "transformers.ipynb",
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "xoZul_o22nIO"
      },
      "source": [
        "# Importing relevant libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "\n",
        "!pip install transformers\n",
        "from transformers import BertTokenizer\n",
        "from transformers import TFBertModel\n",
        "\n",
        "import pickle\n",
        "from tensorflow import keras \n",
        "\n",
        "import os\n",
        "\n",
        "# Global Variables\n",
        "data_size = 50000\n",
        "model_name = \"bert-base-uncased\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cuja9Dki27x7"
      },
      "source": [
        "print(\"Downloading dataset\")\n",
        "!gdown --id 1ne-nT-rA26lzZTVAnWk9bKOFs6XdqlL9"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SpUDDnK7-ztX"
      },
      "source": [
        "# Preprocessing functions\n",
        "def tokenize(text_doc):\n",
        "    # returns generator object for optimization\n",
        "    return (token.lemma_.lower() for token in text_doc if (not token.is_stop) & (token.lemma_ != '-PRON-') & (not token.is_punct) & (not token.text.isdigit()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdRRx8RrZVrd"
      },
      "source": [
        "imdb = pd.read_csv('/content/treebank.csv')\n",
        "imdb = imdb.iloc[:data_size]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UugPlTdrZvAN"
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}